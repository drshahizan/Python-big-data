<a href="https://github.com/drshahizan/Python-big-data/stargazers"><img src="https://img.shields.io/github/stars/drshahizan/Python-big-data" alt="Stars Badge"/></a>
<a href="https://github.com/drshahizan/Python-big-data/network/members"><img src="https://img.shields.io/github/forks/drshahizan/Python-big-data" alt="Forks Badge"/></a>
<a href="https://github.com/drshahizan/Python-big-data/pulls"><img src="https://img.shields.io/github/issues-pr/drshahizan/Python-big-data" alt="Pull Requests Badge"/></a>
<a href="https://github.com/drshahizan/Python-big-data/issues"><img src="https://img.shields.io/github/issues/drshahizan/Python-big-data" alt="Issues Badge"/></a>
<a href="https://github.com/drshahizan/Python-big-data/graphs/contributors"><img alt="GitHub contributors" src="https://img.shields.io/github/contributors/drshahizan/Python-big-data?color=2b9348"></a>
![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fdrshahizan%2FPython-big-data&labelColor=%23d9e3f0&countColor=%23697689&style=flat)

Don't forget to hit the :star: if you like this repo.

# 1. Big Data: Pandas
Big Data processing with **Pandas**, a powerful Python library for data manipulation and analysis, involves implementing strategies to handle large datasets efficiently. Scaling to sizable datasets requires adopting techniques such as processing data in smaller chunks using the '**chunksize**' parameter in Pandas **read_csv** function. This approach facilitates reading and processing large datasets in more manageable portions, preventing memory overload. To further optimize memory usage, it's essential to leverage Pandas' features like data types optimization, using more memory-efficient data types when possible. Additionally, utilizing advanced functionalities like the '**skiprows**' parameter and filtering columns during data import can significantly enhance performance. By mastering these strategies, one can effectively manage and analyze vast datasets in Python with **Pandas**, ensuring both computational efficiency and memory optimization in the face of **Big Data** challenges

- [Top 10 Python Libraries Data Scientists should know](https://www.edureka.co/blog/python-libraries/)
- [Top 5 Python Libraries For Big Data](https://www.geeksforgeeks.org/top-5-python-libraries-for-big-data/)
- [Python Pandas Dataframe Tutorial for Beginners](https://www.projectpro.io/article/python-pandas-dataframe-tutorials/405)
- [4 strategies how to deal with large datasets in Pandas](https://www.codementor.io/@guidotournois/4-strategies-to-deal-with-large-datasets-using-pandas-qdw3an95k)
- [Scaling to large dataset](https://pandas.pydata.org/docs/user_guide/scale.html)
- [3 ways to deal with large datasets in Python](https://towardsdatascience.com/5-ways-to-deal-with-large-datasets-in-python-9a80786c4182)
- [Reducing Pandas memory usage](https://pythonspeed.com/articles/pandas-load-less-data/)
- [How To Handle Large Datasets in Python With Pandas](https://pythonsimplified.com/how-to-handle-large-datasets-in-python-with-pandas/)
- [Efficient Pandas: Using Chunksize for Large Datasets](https://towardsai.net/p/data-science/efficient-pandas-using-chunksize-for-large-data-sets-c66bf3037f93)
- [How did I convert the 33 GB Dataset into a 3 GB file Using Pandas?](https://medium.com/aatomz-research/how-did-i-convert-the-33-gb-dataset-into-a-3-gb-file-using-pandas-b21d8da205c0)
- [Video: How to work with big data files (5gb+) in Python Pandas!](https://youtu.be/l34l-90UF7U)
- [Loading large datasets in Panda](https://towardsdatascience.com/loading-large-datasets-in-pandas-11bdddd36f7b)
- [Video: How to Read Very Big Files With SQL and Pandas in Python](https://youtu.be/xKMyk4wDHnQ)
- [Scaling to large datasets](https://pandas.pydata.org/pandas-docs/stable/user_guide/scale.html)
- [Video: How to Handle Very Large Datasets in Python Pandas (Tips & Tricks)](https://www.youtube.com/watch?v=E7iwJUzm3Jo&t=2s)
- [Video: 3 Tips to Read Very Large CSV as Pandas Dataframe](https://www.youtube.com/watch?v=GmG3dXhehJc&t=1s)
- [Kaggle: Largest Datasets](https://www.kaggle.com/code/benhamner/competitions-with-largest-datasets)
- [EDA for Amazon books reviews](https://www.kaggle.com/code/mohamedbakhet/eda-for-amazon-books-reviews/notebook)

## Contribution üõ†Ô∏è
Please create an [Issue](https://github.com/drshahizan/Python_EDA/issues) for any improvements, suggestions or errors in the content.

You can also contact me using [Linkedin](https://www.linkedin.com/in/drshahizan/) for any other queries or feedback.

[![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fdrshahizan&labelColor=%23697689&countColor=%23555555&style=plastic)](https://visitorbadge.io/status?path=https%3A%2F%2Fgithub.com%2Fdrshahizan)
![](https://hit.yhype.me/github/profile?user_id=81284918)

