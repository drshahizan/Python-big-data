<a href="https://github.com/drshahizan/Python-big-data/stargazers"><img src="https://img.shields.io/github/stars/drshahizan/Python-big-data" alt="Stars Badge"/></a>
<a href="https://github.com/drshahizan/Python-big-data/network/members"><img src="https://img.shields.io/github/forks/drshahizan/Python-big-data" alt="Forks Badge"/></a>
<a href="https://github.com/drshahizan/Python-big-data/pulls"><img src="https://img.shields.io/github/issues-pr/drshahizan/Python-big-data" alt="Pull Requests Badge"/></a>
<a href="https://github.com/drshahizan/Python-big-data/issues"><img src="https://img.shields.io/github/issues/drshahizan/Python-big-data" alt="Issues Badge"/></a>
<a href="https://github.com/drshahizan/Python-big-data/graphs/contributors"><img alt="GitHub contributors" src="https://img.shields.io/github/contributors/drshahizan/Python-big-data?color=2b9348"></a>
![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fdrshahizan%2FPython-big-data&labelColor=%23d9e3f0&countColor=%23697689&style=flat)

Don't forget to hit the :star: if you like this repo.

# Better Choices for Handling Big Datasets than Pandas

While Pandas is a powerful and widely-used library for data manipulation and analysis in Python, it may not always be the most efficient choice for processing extremely large datasets. Here are eight alternatives to Pandas that are specifically designed to handle large datasets:

| No. | Library         | Description | GitHub |
|-----:|-----------------|------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------:|
| 1   | **[Dask](https://dask.org/)**         | Dask is a parallel computing library that integrates with Pandas and NumPy to provide scalable data processing capabilities. A library that provides parallel execution on larger-than-memory datasets, using many smaller pandas DataFrames. It has a similar API to pandas and supports lazy evaluation. It allows you to work with larger-than-memory datasets by parallelizing computations and efficiently using parallel computing resources. Dask supports out-of-core computing, enabling it to process datasets that don't fit into memory. | [:octocat:](https://github.com/dask/dask) |
| 2   | **[Modin](https://modin.readthedocs.io/)**        | A library that uses Ray or Dask to speed up pandas operations. It has seamless integration and compatibility with existing pandas code. | [:octocat:](https://github.com/modin-project/modin) |
| 3   | **[Data Table](https://datatable.readthedocs.io/)**   | A library for manipulating tabular data, with fast and memory-efficient operations. It can handle up to 100GB of data on a single-node machine and has interoperability with pandas/NumPy/pure Python. | [:octocat:](https://github.com/h2oai/datatable) |
| 4   | **[Polars](https://pola-rs.github.io/polars/)**       | A library that offers a comprehensive Python API for DataFrames and a query engine for data models. It uses the secure Arrow2 implementation of the Apache Arrow specification, which makes it highly efficient for processing large amounts of data. | [:octocat:](https://github.com/pola-rs/polars) |
| 5   | **[Vaex](https://vaex.io/)**         | A library for lazy, out-of-core DataFrames, to visualize and explore big tabular datasets. It delays operations until necessary, reducing memory usage and time. It also supports interactive visualization with histograms, density plots, and 3d volume rendering. | [:octocat:](https://github.com/vaexio/vaex) |
| 6   | **[Pyspark](spark.apache.org/)**      | A library that provides a Python interface to Apache Spark, a distributed computing framework for large-scale data processing. It allows users to write Spark applications using Python and leverage the power of Spark SQL, MLlib, Streaming, and GraphX. | [:octocat:](https://github.com/apache/spark) |
| 7   | **[Koalas](https://koalas.readthedocs.io/)**       | A library that bridges the gap between pandas and Apache Spark, by providing a pandas-like API on top of Spark. It enables users to scale their existing pandas code to run on large datasets, without much code change. | [:octocat:](https://github.com/databricks/koalas) |
| 8   | **[CuDF](https://docs.rapids.ai/api/cudf/stable/)** | A library that implements a GPU-accelerated DataFrame, which is compatible with pandas. It allows users to perform data manipulation, join, groupby, and statistical operations on GPU data, with significant speedup and memory saving. | [:octocat:](https://github.com/rapidsai/cudf) |

## Contribution üõ†Ô∏è
Please create an [Issue](https://github.com/drshahizan/Python_EDA/issues) for any improvements, suggestions or errors in the content.

You can also contact me using [Linkedin](https://www.linkedin.com/in/drshahizan/) for any other queries or feedback.

[![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fdrshahizan&labelColor=%23697689&countColor=%23555555&style=plastic)](https://visitorbadge.io/status?path=https%3A%2F%2Fgithub.com%2Fdrshahizan)
![](https://hit.yhype.me/github/profile?user_id=81284918)
